# Aipha Data Processor

Este documento proporciona una explicaciÃ³n tÃ©cnica detallada del `data_system` de Aipha, diseÃ±ado para ser comprendido tanto por desarrolladores como por modelos de lenguaje (LLMs).

## ğŸ¯ PropÃ³sito
El `data_system` es el motor de adquisiciÃ³n y persistencia de datos de Aipha. Su objetivo es descargar datos histÃ³ricos de mercado (especÃ­ficamente klines de Binance), procesarlos en DataFrames de Pandas y almacenarlos de forma eficiente en una base de datos local **DuckDB** para anÃ¡lisis posterior.

## ğŸ—ï¸ Arquitectura y Flujo de Datos

El sistema sigue un diseÃ±o modular con separaciÃ³n clara de responsabilidades:

```mermaid
graph TD
    A[client.py: ApiClient] -->|Realiza peticiones HTTP| B[fetcher.py: BinanceKlinesFetcher]
    C[templates.py: DataTemplates] -->|Define quÃ© descargar| B
    D[storage.py: StorageManager] -->|Gestiona persistencia de| C
    B -->|Procesa ZIP/CSV| E[Pandas DataFrame]
    E -->|Se guarda en| F[(data_processor/data/aipha_data.duckdb)]
    G[main.py: Automation] -->|Coordina carga masiva| D
```

## ğŸ§© Componentes Detallados

### 1. `client.py` (ApiClient)
- **FunciÃ³n**: Cliente HTTP robusto basado en `requests.Session`.
- **LÃ³gica**: Maneja reintentos, timeouts, cabeceras persistentes y streaming para descargas de archivos grandes.
- **Punto clave para LLMs**: Es agnÃ³stico a la fuente de datos; solo se encarga de la capa de transporte.

### 2. `templates.py` (Data Contracts)
- **FunciÃ³n**: Define el "quÃ©" se solicita.
- **Componentes**:
    - `BaseDataRequestTemplate`: Clase base abstracta con registro automÃ¡tico de subclases.
    - `KlinesDataRequestTemplate`: Define sÃ­mbolo, intervalo, y rango de fechas (`start_date`, `end_date`).
- **LÃ³gica**: Incluye mÃ©todos de serializaciÃ³n (`to_dict`, `from_dict`) para persistencia en JSON.

### 3. `fetcher.py` (BinanceKlinesFetcher)
- **FunciÃ³n**: El "cerebro" de la adquisiciÃ³n de datos.
- **LÃ³gica**:
    1. Construye URLs para Binance Vision.
    2. Descarga archivos ZIP usando el `ApiClient`.
    3. Extrae y parsea CSVs directamente a DataFrames.
    4. Implementa una cachÃ© local en `data_processor/data/test_downloaded_data` para evitar descargas duplicadas.

### 4. `storage.py` (Persistence Layer)
- **FunciÃ³n**: Gestiona el almacenamiento a largo plazo.
- **DuckDB**: Utiliza DuckDB para persistencia analÃ­tica. Permite insertar DataFrames de Pandas de forma casi instantÃ¡nea.
- **TemplateManager**: Guarda y carga las configuraciones de los templates en un archivo JSON (`data_processor/data/test_project_templates.json`).

### 5. `main.py` (Orchestration)
- **FunciÃ³n**: Punto de entrada para tareas automatizadas.
- **LÃ³gica**: Permite la carga masiva de archivos CSV externos a DuckDB, facilitando la ingesta de datos de otras fuentes.

## ğŸš€ CÃ³mo funciona el flujo completo (End-to-End)

1. **DefiniciÃ³n**: Se crea un `KlinesDataRequestTemplate` con los parÃ¡metros deseados.
2. **AdquisiciÃ³n**: El `BinanceKlinesFetcher` descarga los dÃ­as necesarios uno a uno.
3. **ConsolidaciÃ³n**: Los datos se limpian y se concatenan en un Ãºnico DataFrame.
4. **Persistencia**: `save_results_to_duckdb` inserta el DataFrame en la tabla correspondiente de DuckDB.
5. **AnÃ¡lisis**: Los datos estÃ¡n listos para ser consultados mediante SQL estÃ¡ndar sobre el archivo `.duckdb`.

## ğŸ“ Estructura de Archivos

```
data_processor/
â”œâ”€â”€ data_system/     # CÃ³digo fuente (MÃ³dulo Python)
â”œâ”€â”€ tests/           # Pruebas (Ver test_integration.py para ejemplo de uso)
â”œâ”€â”€ docs/            # DocumentaciÃ³n tÃ©cnica y guÃ­as
â”œâ”€â”€ data/            # DuckDB, CachÃ© de descargas y Templates JSON
â”œâ”€â”€ requirements.txt # Dependencias (requests, pandas, duckdb)
â””â”€â”€ logging_config.py# ConfiguraciÃ³n centralizada de logs
```

## ğŸ› ï¸ VerificaciÃ³n
Para validar que todo el sistema funciona correctamente, ejecuta el test de integraciÃ³n:
```bash
python3 data_processor/tests/data_system/test_integration.py
```
Este test simula el flujo completo desde la descarga hasta la persistencia en DuckDB.
